deploy:
  phases:
    install:
      commands:
      - npm install -g aws-cdk@2.20.0
      - pip install -r requirements.txt
    build:
      commands:
      - cdk deploy --require-approval never --progress events --app "python app.py" --outputs-file ./cdk-exports.json
      # Here we export some env vars
      - export ADDF_MODULE_METADATA=$(python -c "import json; file=open('cdk-exports.json'); print(json.load(file)['addf-${ADDF_DEPLOYMENT_NAME}-${ADDF_MODULE_NAME}']['metadata'])")
      - export DAG_ROLE=$(echo ${ADDF_MODULE_METADATA} | jq -r ".DagRoleArn")
      - export ON_DEMAND_JOB_QUEUE_ARN=$(echo ${ADDF_MODULE_METADATA} | jq -r ".OnDemandJobQueueArn")
      - export SPOT_JOB_QUEUE_ARN=$(echo ${ADDF_MODULE_METADATA} | jq -r ".SpotJobQueueArn")
      - export FARGATE_JOB_QUEUE_ARN=$(echo ${ADDF_MODULE_METADATA} | jq -r ".FargateJobQueueArn")
      - export DYNAMODB_TABLE=$(echo ${ADDF_MODULE_METADATA} | jq -r ".DynamoDbTableName")
      - export SOURCE_BUCKET=$(echo ${ADDF_MODULE_METADATA} | jq -r ".SourceBucketName")
      - export TARGET_BUCKET=$(echo ${ADDF_MODULE_METADATA} | jq -r ".TargetBucketName")
      - export ECR_REPO_NAME=$(echo ${ADDF_MODULE_METADATA} | jq -r ".EcrRepoName")
      - export REPOSITORY_URI=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$ECR_REPO_NAME
      # - Here we write env values into the dag_config.py file for use by the DAGs
      - echo "DEPLOYMENT_NAME = '${ADDF_DEPLOYMENT_NAME}'" >> demo_dags/dag_config.py
      - echo "MODULE_NAME = '${ADDF_MODULE_NAME}'" >> demo_dags/dag_config.py
      - echo "DAG_ROLE = '${DAG_ROLE}'" >> demo_dags/dag_config.py
      - echo "DAG_IMAGE = '${REPOSITORY_URI}:${IMAGE_TAG}'" >> demo_dags/dag_config.py
      - echo "ECR_REPO_NAME = '${ECR_REPO_NAME}'" >> demo_dags/dag_config.py
      - echo "REGION = '${AWS_DEFAULT_REGION}'" >> demo_dags/dag_config.py
      - echo "ACCOUNT_ID = '${AWS_ACCOUNT_ID}'" >> demo_dags/dag_config.py
      - echo "ON_DEMAND_JOB_QUEUE_ARN = '${ON_DEMAND_JOB_QUEUE_ARN}'" >> demo_dags/dag_config.py
      - echo "SPOT_JOB_QUEUE_ARN = '${SPOT_JOB_QUEUE_ARN}'" >> demo_dags/dag_config.py
      - echo "FARGATE_JOB_QUEUE_ARN = '${FARGATE_JOB_QUEUE_ARN}'" >> demo_dags/dag_config.py
      - echo "SRC_BUCKET = '${SOURCE_BUCKET}'" >> demo_dags/dag_config.py
      - echo "TARGET_BUCKET = '${TARGET_BUCKET}'" >> demo_dags/dag_config.py
      - echo "DYNAMODB_TABLE = '${DYNAMODB_TABLE}'" >> demo_dags/dag_config.py
      - export COMMIT_HASH=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7)
      - export IMAGE_TAG=${COMMIT_HASH:=latest}
      - aws ecr describe-repositories --repository-names ${ECR_REPO_NAME} || aws ecr create-repository --repository-name ${ECR_REPO_NAME}
      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
      # Copy DAG files to S3
      - aws s3 cp --recursive demo_dags/ s3://$ADDF_PARAMETER_DAG_BUCKET_NAME/$ADDF_PARAMETER_DAG_PATH/demo_dags/
      # - Building the Docker image(s)...
      - cd images/processing-mock && docker build -t $REPOSITORY_URI:latest .
      - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$IMAGE_TAG
      - docker push $REPOSITORY_URI:latest && docker push $REPOSITORY_URI:$IMAGE_TAG
destroy:
  phases:
    install:
      commands:
      - npm install -g aws-cdk@2.20.0
      - pip install -r requirements.txt
    build:
      commands:
      # Remove DAG files
      - aws s3 rm --recursive s3://$ADDF_PARAMETER_DAG_BUCKET_NAME/$ADDF_PARAMETER_DAG_PATH/poc2_batch_dags
      - cdk destroy --force --app "python app.py"

